{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image as PImage\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import albumentations as A\n",
    "from typing import List\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = './train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>grapheme_root</th>\n",
       "      <th>vowel_diacritic</th>\n",
       "      <th>consonant_diacritic</th>\n",
       "      <th>grapheme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train_0</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>ক্ট্রো</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Train_1</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>হ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Train_2</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>খ্রী</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Train_3</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>র্টি</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Train_4</td>\n",
       "      <td>71</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>থ্রো</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_id  grapheme_root  vowel_diacritic  consonant_diacritic grapheme\n",
       "0  Train_0             15                9                    5   ক্ট্রো\n",
       "1  Train_1            159                0                    0        হ\n",
       "2  Train_2             22                3                    5     খ্রী\n",
       "3  Train_3             53                2                    2     র্টি\n",
       "4  Train_4             71                9                    5     থ্রো"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_ = pd.read_csv('./train.csv')\n",
    "train_df_[['grapheme_root', 'vowel_diacritic', 'consonant_diacritic']] = train_df_[['grapheme_root', 'vowel_diacritic', 'consonant_diacritic']].astype('uint8')\n",
    "train_df_.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    train_df = pd.merge(pd.read_parquet(os.path.join(DATA_FOLDER, 'train_image_data_{}.parquet'.format(i))),\n",
    "                        train_df_, on='image_id').drop(['image_id'], axis=1)\n",
    "#to image\n",
    "train_labels = train_df[['grapheme_root','vowel_diacritic','consonant_diacritic','grapheme']]\n",
    "train_df.drop(['grapheme_root','vowel_diacritic','consonant_diacritic','grapheme'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "train_labels['vowel_consonant_diacritic_pair'] = train_labels['vowel_diacritic'].astype(str) + '_' + train_labels['consonant_diacritic'].astype(str)\n",
    "train_labels['test_fold'] = 0 \n",
    "for idx, (train_index, test_index) in enumerate(skf.split(X = train_labels['vowel_consonant_diacritic_pair'], \n",
    "                                                          y = train_labels['vowel_consonant_diacritic_pair'], \n",
    "                                                          groups=train_labels['vowel_consonant_diacritic_pair'])):\n",
    "    train_labels['test_fold'][test_index] = idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare Callbacks and Dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, \n",
    "                 df, \n",
    "                 labels,\n",
    "                 transforms=None):\n",
    "        \n",
    "        self.df = df\n",
    "        self.labels = labels\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        flattened_image = self.df.iloc[idx].values.astype(np.uint8)\n",
    "        image = np.expand_dims(flattened_image.reshape(137, 236), 2)\n",
    "        \n",
    "        grapheme_root =  self.labels['grapheme_root'].values[idx]\n",
    "        vowel_diacritic = self.labels['vowel_diacritic'].values[idx]\n",
    "        consonant_diacritic = self.labels['consonant_diacritic'].values[idx]\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            augmented = self.transforms(image=image)\n",
    "            image = augmented['image']\n",
    "        \n",
    "        image = torch.from_numpy(image.transpose((2,0,1)))\n",
    "        grapheme_root = torch.tensor(grapheme_root) \n",
    "        vowel_diacritic = torch.tensor(vowel_diacritic) \n",
    "        consonant_diacritic = torch.tensor(consonant_diacritic) \n",
    "        \n",
    "        output_dict  = {\n",
    "            'grapheme_root' : grapheme_root, \n",
    "            'vowel_diacritic' : vowel_diacritic, \n",
    "            'consonant_diacritic' : consonant_diacritic, \n",
    "            'image' : image\n",
    "                       }\n",
    "\n",
    "        return output_dict\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make train and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "num_workers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "train_fold_idx = train_labels['test_fold'] != idx\n",
    "val_fold_idx = train_labels['test_fold'] == idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_val = A.Compose([\n",
    "    A.Normalize(mean=(0.485), std=(0.229))\n",
    "],\n",
    "        p=1.0)  \n",
    "train_dataset = ImageDataset(df = train_df.loc[train_fold_idx, :], \n",
    "                             labels = train_labels.loc[train_fold_idx, :], \n",
    "                             transforms = aug_val\n",
    "                            )\n",
    "val_dataset = ImageDataset(df = train_df.loc[val_fold_idx, :],\n",
    "                           labels = train_labels.loc[train_fold_idx, :], \n",
    "                           transforms = aug_val\n",
    "                          )\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True,\n",
    "    shuffle=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True,\n",
    "    shuffle=False   \n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Callbacks for catalyst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "class TaskMetricCallback(Callback):\n",
    "    '''\n",
    "    Proposed metrics:\n",
    "    import numpy as np\n",
    "    import sklearn.metrics\n",
    "\n",
    "    scores = []\n",
    "    for component in ['grapheme_root', 'consonant_diacritic', 'vowel_diacritic']:\n",
    "        y_true_subset = solution[solution[component] == component]['target'].values\n",
    "        y_pred_subset = submission[submission[component] == component]['target'].values\n",
    "        scores.append(sklearn.metrics.recall_score(\n",
    "            y_true_subset, y_pred_subset, average='macro'))\n",
    "    final_score = np.average(scores, weights=[2,1,1])\n",
    "    '''\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        input_key: str = \"targets\", \n",
    "        output_key: str = \"logits\",\n",
    "        prefix: str = \"macro_f1\", \n",
    "        ignore_index=None\n",
    "    ):\n",
    "        super().__init__(CallbackOrder.Metric)\n",
    "        self.metric_fn = lambda outputs, targets: recall_score(targets, outputs, average=\"macro\")\n",
    "        self.prefix = prefix\n",
    "        self.output_key = output_key\n",
    "        self.input_key = input_key\n",
    "        self.outputs = []\n",
    "        self.targets = []\n",
    "        self.ignore_index = ignore_index\n",
    "\n",
    "    def on_batch_end(self, state: RunnerState):\n",
    "        outputs = to_numpy(state.output[self.output_key])\n",
    "        targets = to_numpy(state.input[self.input_key])\n",
    "\n",
    "        num_classes = outputs.shape[1]\n",
    "        outputs = np.argmax(outputs, axis=1)\n",
    "\n",
    "        if self.ignore_index is not None:\n",
    "            mask = targets != self.ignore_index\n",
    "            outputs = outputs[mask]\n",
    "            targets = targets[mask]\n",
    "\n",
    "        outputs = [np.eye(num_classes)[y] for y in outputs]\n",
    "        targets = [np.eye(num_classes)[y] for y in targets]\n",
    "\n",
    "        self.outputs.extend(outputs)\n",
    "        self.targets.extend(targets)\n",
    "\n",
    "        # metric = self.metric_fn(self.targets, self.outputs)\n",
    "        # state.metrics.add_batch_value(name=self.prefix, value=metric)\n",
    "\n",
    "    def on_loader_start(self, state):\n",
    "        self.outputs = []\n",
    "        self.targets = []\n",
    "\n",
    "    def on_loader_end(self, state):\n",
    "        metric_name = self.prefix\n",
    "        targets = np.array(self.targets)\n",
    "        outputs = np.array(self.outputs)\n",
    "\n",
    "        metric = self.metric_fn(outputs, targets)\n",
    "        state.metrics.epoch_values[state.loader_name][metric_name] = metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
